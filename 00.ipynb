{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02b6d18-8517-433f-98e2-f4b42e54983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in /media/indika/Sync/anaconda3/lib/python3.8/site-packages (0.12.5)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /media/indika/Sync/anaconda3/lib/python3.8/site-packages (from wandb) (3.19.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: PyYAML in /home/indika/.local/lib/python3.8/site-packages (from wandb) (5.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /home/indika/.local/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (8.0.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/indika/.local/lib/python3.8/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/indika/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/indika/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/indika/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/indika/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/indika/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/indika/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.2)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /home/indika/.local/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cde04b-c8ba-4562-af88-240f612a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'chatbot'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b22c731-d112-45e5-94fc-0c9357c9091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7b1328-c77d-40f4-9394-821a084de524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$', '100']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('$100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501fdfc6-971f-4148-b69f-3751ff57321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf52013-169b-497e-8747-d77a13e5edfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd8a40c-2857-4536-bbb9-d7be6d0795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumerate(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f29781-ff27-4831-ad1d-002f836322d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdafe522-52fd-4dc7-974a-a3e9ca44ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./data.csv').sample(frac=1)[:3250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3998530b-6a3d-41a2-916f-8835f6dcf6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('./cleaned-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf85f97-02cb-4988-96f3-b6381d3b0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('./data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c254427e-502e-4ca4-a225-6672b90549be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'greeting',\n",
       " 'patterns': ['Hi',\n",
       "  'Hey',\n",
       "  'How are you',\n",
       "  'Is anyone there?',\n",
       "  'Hello',\n",
       "  'Good day'],\n",
       " 'responses': ['Hey :-)',\n",
       "  'Hello, thanks for visiting',\n",
       "  'Hi there, what can I do for you?',\n",
       "  'Hi there, how can I help?']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(data.iloc[0]['intents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a569ea0-1fe2-4e5f-9275-78fd2579ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {'Question':[],'Tag':[]}\n",
    "responses = {'Tag':[],'Response':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53bed457-9186-4bae-832b-bb5f66500914",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    info = data.iloc[i]['intents']\n",
    "    for q in list(info['patterns']):\n",
    "        new_data['Tag'].append(info['tag'])\n",
    "        new_data['Question'].append(q)\n",
    "    for r in list(info['responses']):\n",
    "        responses['Tag'].append(info['tag'])\n",
    "        responses['Response'].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d15f73f-531e-4b4d-a79f-c3f6f81ac6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3bed852-1e27-494f-81c1-c1046b204f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "547e5814-7377-4c23-a3f0-6b1391d86358",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f8d298-9cb2-4293-8c9a-22e133a1e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Question']\n",
    "y = data['Tag']\n",
    "X_words = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ac50f1-c46e-47bc-b585-67a28386c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y:\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "152b6f57-55bd-4698-968c-340fab23beba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greeting': 1,\n",
       " 'goodbye': 2,\n",
       " 'thanks': 3,\n",
       " 'items': 4,\n",
       " 'payments': 5,\n",
       " 'delivery': 6,\n",
       " 'funny': 7}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a1a4d6-a887-43d2-b7d0-ed53fb4a3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 9243.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_X = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    X_words.extend(new_X)\n",
    "    \n",
    "    data.append([\n",
    "        X_words,\n",
    "        labels[y_batch]-1\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1755149-ef56-4e67-810a-a87d4ca7d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words = sorted(set(X_words))\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e5a85e-9dc2-438f-a1ab-70b16b6c61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81dc1db4-b804-47ca-9df8-20597fec746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 1072.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for input_sentence,output_sentence in tqdm(data):\n",
    "    X.append(bag_of_words(input_sentence,X_words))\n",
    "    y.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39003dad-6d7f-4634-806a-00478b3b99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.0125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).long()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).long()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).long()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d31e399-6da9-418f-981f-0abc4741390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e1e6bc4-332b-4fb4-932c-76a8be59844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y,):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9119755-0468-4d19-8962-8461f4ac5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, hidden_size=8,):\n",
    "        super().__init__()\n",
    "        self.l1 = Linear(len(X_words), hidden_size) \n",
    "        self.l2 = Linear(hidden_size, hidden_size) \n",
    "        self.l3 = Linear(hidden_size, len(labels))\n",
    "        self.relu = ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4a98f8-f33a-4ede-8230-1968fdfe8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b06b2c-0309-4456-a171-73d81768fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:15k7tboy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 656103... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.03MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">baseline</strong>: <a href=\"https://wandb.ai/ranuga-d/chatbot/runs/15k7tboy\" target=\"_blank\">https://wandb.ai/ranuga-d/chatbot/runs/15k7tboy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211022_010052-15k7tboy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:15k7tboy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/chatbot/runs/35slu1u9\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/chatbot\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target' in call to _thnn_nll_loss_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3cba9789b331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/indika/Sync/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/indika/Sync/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/indika/Sync/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target' in call to _thnn_nll_loss_forward"
     ]
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    preds = model(X_train)\n",
    "    loss = criterion(preds,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':get_loss(model,X_train,y_train,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':get_accuracy(model,X_train,y_train)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a07c2-363f-4867-aeab-c204bcc8ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to('cpu'),'model.pt')\n",
    "torch.save(model.to('cpu'),'model.pth')\n",
    "torch.save(model.to('cpu').state_dict(),'model-sd.pt')\n",
    "torch.save(model.to('cpu').state_dict(),'model-sd.pth')\n",
    "torch.save(X_words,'words.pt')\n",
    "torch.save(X_words,'words.pth')\n",
    "torch.save(data,'data.pt')\n",
    "torch.save(data,'data.pth')\n",
    "torch.save(labels,'labels.pt')\n",
    "torch.save(labels,'labels.pth')\n",
    "torch.save(labels_r,'labels_r.pt')\n",
    "torch.save(labels_r,'labels_r.pth')\n",
    "torch.save(idx,'idx.pt')\n",
    "torch.save(idx,'idx.pth')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(y_test,'y_test.pth')\n",
    "torch.save(y,'y.pt')\n",
    "torch.save(y,'y.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371bd30-bc66-4ddf-86fc-8f55f563328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.argmax(model(torch.from_numpy(bag_of_words(['hi','how','are','you'],X_words)).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d3286-2e07-4106-8177-6665d02df8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d253656-1a1b-4177-aaf2-100cc31de582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90455126-6688-4bdb-ae92-08692be2d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.to_csv('./responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c13ae-ee84-4c99-bc46-dd25b6e216ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd07338908a6901250255932625ba4b5c32a9d91564d69b39dc5095100e5c96b0b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
